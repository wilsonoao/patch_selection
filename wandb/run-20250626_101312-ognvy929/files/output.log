dilated_ratio:  [1, 2, 4, 8, 16]
segment_length:  [1024, 5792, 32768, 185363, 1048576]
Number of trainable LongNet parameters:  85148160
Global Pooling: False
slide_encoder.pth: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345M/345M [00:35<00:00, 9.63MB/s]
[92m Successfully Loaded Pretrained GigaPath model from hf_hub:prov-gigapath/prov-gigapath [00m
[768, 512, 256]
 12%|██████████████████▋                                                                                                                                            | 61/518 [00:02<00:18, 24.41it/s]
ppo update
🔍 rewards: tensor([0.2199, 0.3556, 0.6715, 0.4246, 0.5879, 0.5348, 0.4691, 0.4839, 0.4811,
        0.5246, 0.5453, 0.5592, 0.5347, 0.5905, 0.5075, 0.6360, 0.5008, 0.6567,
        0.6515, 0.6595, 0.4006, 0.6883, 0.6517, 0.3964, 0.6906, 0.3799, 0.4197,
        0.7353, 0.6919, 0.7181, 0.4605, 0.6532, 0.4085, 0.4304, 0.6741, 0.6662,
        0.5163, 0.4854, 0.4794, 0.5408, 0.6067, 0.4965, 0.6355, 0.6529, 0.3805,
        0.6331, 0.6570, 0.4247, 0.7265, 0.6436, 0.2850, 0.3489, 0.3477, 0.4536,
        0.3752, 0.5505, 0.5217, 0.5836, 0.5625, 0.4930, 0.6245, 0.4441, 0.6841,
        0.6377], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5383012890815735
rewards std: 0.1205616444349289
any NaN in rewards: False
tensor([[ 0.0162,  0.1326, -0.5882,  ...,  0.0186, -0.2207,  0.3022],
        [-0.0499, -0.0135, -0.3803,  ...,  0.0608,  0.0042,  0.0804],
        [ 0.0659,  0.0116, -0.1991,  ...,  0.1997,  0.0928,  0.0041],
        ...,
        [ 0.0953, -0.0414, -0.2117,  ...,  0.1375, -0.0603,  0.0416],
        [-0.0149, -0.1616, -0.2877,  ..., -0.0489, -0.1155,  0.2332],
        [ 0.0645,  0.0191, -0.1177,  ...,  0.1060, -0.0182,  0.2770]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0162,  0.1326, -0.5882,  ...,  0.0186, -0.2207,  0.3022],
        [-0.0499, -0.0135, -0.3803,  ...,  0.0608,  0.0042,  0.0804],
        [ 0.0659,  0.0116, -0.1991,  ...,  0.1997,  0.0928,  0.0041],
        ...,
        [ 0.0953, -0.0414, -0.2117,  ...,  0.1375, -0.0603,  0.0416],
        [-0.0149, -0.1616, -0.2877,  ..., -0.0489, -0.1155,  0.2332],
        [ 0.0645,  0.0191, -0.1177,  ...,  0.1060, -0.0182,  0.2770]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0162,  0.1326, -0.5882,  ...,  0.0186, -0.2207,  0.3022],
        [-0.0499, -0.0135, -0.3803,  ...,  0.0608,  0.0042,  0.0804],
        [ 0.0659,  0.0116, -0.1991,  ...,  0.1997,  0.0928,  0.0041],
        ...,
        [ 0.0953, -0.0414, -0.2117,  ...,  0.1375, -0.0603,  0.0416],
        [-0.0149, -0.1616, -0.2877,  ..., -0.0489, -0.1155,  0.2332],
        [ 0.0645,  0.0191, -0.1177,  ...,  0.1060, -0.0182,  0.2770]],
       device='cuda:0')
torch.Size([64, 30])
ppo update
🔍 rewards: tensor([0.3383, 0.3452, 0.6735, 0.3249, 0.6961, 0.4106, 0.7011, 0.6994, 0.6207,
        0.3736, 0.4050, 0.6343, 0.4644, 0.5281, 0.4968, 0.6157, 0.4919, 0.5883,
        0.4870, 0.5881, 0.4120, 0.3852, 0.4669, 0.7011, 0.6624, 0.6732, 0.6339,
        0.6855, 0.6831, 0.6676, 0.6548, 0.4067, 0.6410, 0.3771, 0.6407, 0.3603,
        0.4020, 0.7440, 0.7771, 0.6265, 0.4618, 0.4616, 0.6616, 0.4289, 0.3709,
        0.5809, 0.5120, 0.5014, 0.6192, 0.7444, 0.6820, 0.6519, 0.3321, 0.4030,
        0.7888, 0.6698, 0.3579, 0.3323, 0.6847, 0.6851, 0.6979, 0.7097, 0.6769,
        0.3221], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5534567832946777
rewards std: 0.14059972763061523
any NaN in rewards: False
tensor([[ 0.1876, -0.1427, -0.2488,  ..., -0.0165, -0.0052,  0.3073],
        [ 0.0815, -0.0211, -0.2045,  ...,  0.0480,  0.0075,  0.0691],
        [-0.0544,  0.2922, -0.2829,  ..., -0.0678,  0.0019,  0.0737],
        ...,
        [ 0.1474, -0.0598, -0.2847,  ...,  0.0784,  0.0084,  0.1811],
        [ 0.0863,  0.0914, -0.3103,  ...,  0.1302, -0.1919,  0.2434],
        [ 0.1587,  0.0123, -0.4098,  ...,  0.0402, -0.1987,  0.2986]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.1876, -0.1427, -0.2488,  ..., -0.0165, -0.0052,  0.3073],
        [ 0.0815, -0.0211, -0.2045,  ...,  0.0480,  0.0075,  0.0691],
        [-0.0544,  0.2922, -0.2829,  ..., -0.0678,  0.0019,  0.0737],
        ...,
        [ 0.1474, -0.0598, -0.2847,  ...,  0.0784,  0.0084,  0.1811],
        [ 0.0863,  0.0914, -0.3103,  ...,  0.1302, -0.1919,  0.2434],
        [ 0.1587,  0.0123, -0.4098,  ...,  0.0402, -0.1987,  0.2986]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.1876, -0.1427, -0.2488,  ..., -0.0165, -0.0052,  0.3073],
        [ 0.0815, -0.0211, -0.2045,  ...,  0.0480,  0.0075,  0.0691],
        [-0.0544,  0.2922, -0.2829,  ..., -0.0678,  0.0019,  0.0737],
        ...,
        [ 0.1474, -0.0598, -0.2847,  ...,  0.0784,  0.0084,  0.1811],
        [ 0.0863,  0.0914, -0.3103,  ...,  0.1302, -0.1919,  0.2434],
        [ 0.1587,  0.0123, -0.4098,  ...,  0.0402, -0.1987,  0.2986]],
       device='cuda:0')
torch.Size([64, 30])
ppo update
🔍 rewards: tensor([0.3743, 0.3681, 0.3630, 0.4639, 0.6160, 0.6529, 0.5898, 0.5507, 0.5815,
        0.4872, 0.4787, 0.5407, 0.5655, 0.4387, 0.4142, 0.5206, 0.6718, 0.5001,
        0.6850, 0.7416, 0.3065, 0.3401, 0.3455, 0.3797, 0.7503, 0.4323, 0.4559,
        0.4269, 0.6581, 0.4929, 0.5570, 0.5469, 0.6060, 0.5100, 0.5077, 0.5987,
        0.5730, 0.4976, 0.5167, 0.5900, 0.5751, 0.5711, 0.4368, 0.5109, 0.5570,
        0.6334, 0.5214, 0.6487, 0.6455, 0.6055, 0.6726, 0.4228, 0.4115, 0.4105,
        0.4193, 0.4121, 0.5796, 0.5801, 0.6104, 0.4750, 0.4981, 0.4858, 0.5912,
        0.6074], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5246543884277344
rewards std: 0.10173133760690689
any NaN in rewards: False
tensor([[ 1.8163e-01,  5.4618e-02, -2.8192e-01,  ...,  7.5973e-02,
         -5.4085e-02,  2.3383e-01],
        [-1.5241e-02, -1.8607e-01, -3.1045e-01,  ..., -1.8023e-01,
         -1.3753e-01,  2.0480e-01],
        [ 4.4150e-02,  1.4110e-01, -3.0259e-01,  ..., -2.8285e-02,
          1.0755e-02,  3.6125e-02],
        ...,
        [ 5.4646e-02, -4.4805e-02, -2.3041e-01,  ..., -2.4999e-02,
         -1.9305e-01,  9.6150e-02],
        [ 3.7709e-02, -9.2685e-02, -1.4662e-01,  ...,  1.4497e-02,
          2.4240e-02,  3.5529e-04],
        [-5.2850e-03,  5.5765e-03, -1.6661e-01,  ...,  3.6664e-01,
          1.5306e-01, -3.6443e-02]], device='cuda:0')
torch.Size([64, 30])
tensor([[ 1.8163e-01,  5.4618e-02, -2.8192e-01,  ...,  7.5973e-02,
         -5.4085e-02,  2.3383e-01],
        [-1.5241e-02, -1.8607e-01, -3.1045e-01,  ..., -1.8023e-01,
         -1.3753e-01,  2.0480e-01],
        [ 4.4150e-02,  1.4110e-01, -3.0259e-01,  ..., -2.8285e-02,
          1.0755e-02,  3.6125e-02],
        ...,
        [ 5.4646e-02, -4.4805e-02, -2.3041e-01,  ..., -2.4999e-02,
         -1.9305e-01,  9.6150e-02],
        [ 3.7709e-02, -9.2685e-02, -1.4662e-01,  ...,  1.4497e-02,
          2.4240e-02,  3.5529e-04],
        [-5.2850e-03,  5.5765e-03, -1.6661e-01,  ...,  3.6664e-01,
          1.5306e-01, -3.6443e-02]], device='cuda:0')
torch.Size([64, 30])
tensor([[ 1.8163e-01,  5.4618e-02, -2.8192e-01,  ...,  7.5973e-02,
         -5.4085e-02,  2.3383e-01],
        [-1.5241e-02, -1.8607e-01, -3.1045e-01,  ..., -1.8023e-01,
         -1.3753e-01,  2.0480e-01],
        [ 4.4150e-02,  1.4110e-01, -3.0259e-01,  ..., -2.8285e-02,
          1.0755e-02,  3.6125e-02],
        ...,
        [ 5.4646e-02, -4.4805e-02, -2.3041e-01,  ..., -2.4999e-02,
         -1.9305e-01,  9.6150e-02],
        [ 3.7709e-02, -9.2685e-02, -1.4662e-01,  ...,  1.4497e-02,
          2.4240e-02,  3.5529e-04],
        [-5.2850e-03,  5.5765e-03, -1.6661e-01,  ...,  3.6664e-01,
          1.5306e-01, -3.6443e-02]], device='cuda:0')
torch.Size([64, 30])
ppo update
🔍 rewards: tensor([0.4388, 0.4762, 0.6085, 0.4911, 0.4678, 0.5762, 0.4348, 0.6969, 0.5252,
        0.4688, 0.5816, 0.5915, 0.5788, 0.4942, 0.5427, 0.5237, 0.5620, 0.6274,
        0.5199, 0.6467, 0.5761, 0.5988, 0.7228, 0.5125, 0.5683, 0.6079, 0.5510,
        0.4599, 0.4935, 0.6249, 0.4255, 0.3932, 0.6648, 0.4618, 0.4047, 0.5635,
        0.5955, 0.5235, 0.6359, 0.5735, 0.5756, 0.5233, 0.5915, 0.5951, 0.6691,
        0.6051, 0.5400, 0.6739, 0.6788, 0.5916, 0.5669, 0.3301, 0.4400, 0.3566,
        0.3989, 0.6762, 0.6955, 0.6652, 0.4736, 0.6068, 0.6449, 0.5315, 0.5991,
        0.4187], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.550910472869873
rewards std: 0.09010227024555206
any NaN in rewards: False
tensor([[ 0.0206,  0.1653, -0.2741,  ...,  0.0378, -0.0125,  0.0924],
        [-0.0069,  0.2911, -0.3977,  ...,  0.0313, -0.0942,  0.1648],
        [ 0.0687,  0.0215, -0.2616,  ...,  0.1953,  0.0669,  0.0440],
        ...,
        [ 0.1896,  0.0285, -0.1538,  ...,  0.0078, -0.0607,  0.0358],
        [-0.0527, -0.1852, -0.1905,  ..., -0.0889, -0.1272,  0.0752],
        [ 0.1622, -0.1463, -0.1431,  ..., -0.1282, -0.0512,  0.2775]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0206,  0.1653, -0.2741,  ...,  0.0378, -0.0125,  0.0924],
        [-0.0069,  0.2911, -0.3977,  ...,  0.0313, -0.0942,  0.1648],
        [ 0.0687,  0.0215, -0.2616,  ...,  0.1953,  0.0669,  0.0440],
        ...,
        [ 0.1896,  0.0285, -0.1538,  ...,  0.0078, -0.0607,  0.0358],
        [-0.0527, -0.1852, -0.1905,  ..., -0.0889, -0.1272,  0.0752],
        [ 0.1622, -0.1463, -0.1431,  ..., -0.1282, -0.0512,  0.2775]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0206,  0.1653, -0.2741,  ...,  0.0378, -0.0125,  0.0924],
        [-0.0069,  0.2911, -0.3977,  ...,  0.0313, -0.0942,  0.1648],
        [ 0.0687,  0.0215, -0.2616,  ...,  0.1953,  0.0669,  0.0440],
        ...,
        [ 0.1896,  0.0285, -0.1538,  ...,  0.0078, -0.0607,  0.0358],
        [-0.0527, -0.1852, -0.1905,  ..., -0.0889, -0.1272,  0.0752],
        [ 0.1622, -0.1463, -0.1431,  ..., -0.1282, -0.0512,  0.2775]],
       device='cuda:0')
torch.Size([64, 30])
ppo update
🔍 rewards: tensor([0.5168, 0.5362, 0.5677, 0.5326, 0.5844, 0.6280, 0.6714, 0.6634, 0.4255,
        0.5251, 0.7232, 0.4824, 0.6201, 0.4939, 0.5495, 0.4917, 0.5852, 0.5866,
        0.4018, 0.5975, 0.6743, 0.6563, 0.3717, 0.7270, 0.6360, 0.4223, 0.7524,
        0.6567, 0.6784, 0.3430, 0.7437, 0.7823, 0.7573, 0.3935, 0.4989, 0.7598,
        0.2920, 0.4519, 0.4687, 0.6390, 0.5063, 0.5985, 0.5221, 0.4856, 0.5067,
        0.6518, 0.4633, 0.4358, 0.5591, 0.6265, 0.4960, 0.5131, 0.4983, 0.4498,
        0.5216, 0.5293, 0.5547, 0.4818, 0.4918, 0.5279, 0.5069, 0.5486, 0.5221,
        0.5011], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5529214143753052
rewards std: 0.10738343745470047
any NaN in rewards: False
tensor([[ 0.0931, -0.0613, -0.2094,  ...,  0.0087, -0.0698,  0.1783],
        [ 0.0433,  0.2499, -0.4779,  ..., -0.1166, -0.2660,  0.2239],
        [ 0.1473, -0.0964, -0.4636,  ...,  0.0217, -0.1412,  0.2768],
        ...,
        [ 0.1283,  0.0643, -0.2441,  ...,  0.1533, -0.1455,  0.1213],
        [ 0.0076, -0.1996, -0.4806,  ..., -0.1141, -0.3149,  0.2394],
        [ 0.1572, -0.0756, -0.2558,  ...,  0.1036,  0.1128,  0.1820]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0931, -0.0613, -0.2094,  ...,  0.0087, -0.0698,  0.1783],
        [ 0.0433,  0.2499, -0.4779,  ..., -0.1166, -0.2660,  0.2239],
        [ 0.1473, -0.0964, -0.4636,  ...,  0.0217, -0.1412,  0.2768],
        ...,
        [ 0.1283,  0.0643, -0.2441,  ...,  0.1533, -0.1455,  0.1213],
        [ 0.0076, -0.1996, -0.4806,  ..., -0.1141, -0.3149,  0.2394],
        [ 0.1572, -0.0756, -0.2558,  ...,  0.1036,  0.1128,  0.1820]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0931, -0.0613, -0.2094,  ...,  0.0087, -0.0698,  0.1783],
        [ 0.0433,  0.2499, -0.4779,  ..., -0.1166, -0.2660,  0.2239],
        [ 0.1473, -0.0964, -0.4636,  ...,  0.0217, -0.1412,  0.2768],
        ...,
        [ 0.1283,  0.0643, -0.2441,  ...,  0.1533, -0.1455,  0.1213],
        [ 0.0076, -0.1996, -0.4806,  ..., -0.1141, -0.3149,  0.2394],
        [ 0.1572, -0.0756, -0.2558,  ...,  0.1036,  0.1128,  0.1820]],
       device='cuda:0')
torch.Size([64, 30])
ppo update
🔍 rewards: tensor([0.7687, 0.6408, 0.3619, 0.6122, 0.7544, 0.6241, 0.3477, 0.6515, 0.6810,
        0.3249, 0.4205, 0.4239, 0.6704, 0.3931, 0.4518, 0.4732, 0.6322, 0.5277,
        0.5967, 0.5869, 0.6607, 0.6292, 0.4239, 0.7404, 0.3340, 0.4132, 0.7032,
        0.7252, 0.3895, 0.6558, 0.6797, 0.7149, 0.7048, 0.4327, 0.7824, 0.7018,
        0.3726, 0.3442, 0.7809, 0.7327, 0.3880, 0.3956, 0.6768, 0.4935, 0.6836,
        0.4916, 0.5263, 0.6272, 0.5934, 0.5524, 0.5335, 0.5583, 0.5255, 0.5897,
        0.3913, 0.3603, 0.6824, 0.4824, 0.7348, 0.6847, 0.4910, 0.6730, 0.4186,
        0.6098], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5629536509513855
rewards std: 0.1363997757434845
any NaN in rewards: False
tensor([[ 0.0011,  0.1208, -0.1378,  ..., -0.0107, -0.0673,  0.1076],
        [ 0.0144,  0.1590, -0.2943,  ...,  0.1183, -0.1461,  0.2949],
        [-0.0849, -0.1638, -0.2860,  ...,  0.1555,  0.0562,  0.1514],
        ...,
        [ 0.0760,  0.1662, -0.3265,  ..., -0.1021, -0.1275,  0.1000],
        [ 0.0578, -0.1080, -0.2972,  ...,  0.3027,  0.1577,  0.0356],
        [ 0.0020,  0.1238, -0.2987,  ...,  0.1000, -0.1071,  0.1372]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0011,  0.1208, -0.1378,  ..., -0.0107, -0.0673,  0.1076],
        [ 0.0144,  0.1590, -0.2943,  ...,  0.1183, -0.1461,  0.2949],
        [-0.0849, -0.1638, -0.2860,  ...,  0.1555,  0.0562,  0.1514],
        ...,
        [ 0.0760,  0.1662, -0.3265,  ..., -0.1021, -0.1275,  0.1000],
        [ 0.0578, -0.1080, -0.2972,  ...,  0.3027,  0.1577,  0.0356],
        [ 0.0020,  0.1238, -0.2987,  ...,  0.1000, -0.1071,  0.1372]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0011,  0.1208, -0.1378,  ..., -0.0107, -0.0673,  0.1076],
        [ 0.0144,  0.1590, -0.2943,  ...,  0.1183, -0.1461,  0.2949],
        [-0.0849, -0.1638, -0.2860,  ...,  0.1555,  0.0562,  0.1514],
        ...,
        [ 0.0760,  0.1662, -0.3265,  ..., -0.1021, -0.1275,  0.1000],
        [ 0.0578, -0.1080, -0.2972,  ...,  0.3027,  0.1577,  0.0356],
        [ 0.0020,  0.1238, -0.2987,  ...,  0.1000, -0.1071,  0.1372]],
       device='cuda:0')
torch.Size([64, 30])
ppo update
🔍 rewards: tensor([0.4742, 0.7012, 0.4733, 0.5999, 0.6369, 0.5906, 0.4727, 0.5698, 0.6209,
        0.5985, 0.7261, 0.5221, 0.7185, 0.6699, 0.6506, 0.4804, 0.4496, 0.7175,
        0.7229, 0.4040, 0.6991, 0.3962, 0.6255, 0.3954, 0.3682, 0.4220, 0.6944,
        0.4628, 0.5092, 0.5807, 0.5393, 0.6228, 0.6606, 0.3747, 0.4032, 0.4194,
        0.6853, 0.4732, 0.6987, 0.5569, 0.4193, 0.5504, 0.5087, 0.5386, 0.5529,
        0.5830, 0.5598, 0.5034, 0.6230, 0.6418, 0.7541, 0.6940, 0.4320, 0.3624,
        0.4330, 0.6283, 0.3439, 0.4205, 0.7315, 0.6352, 0.4555, 0.7172, 0.6466,
        0.4853], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5563647747039795
rewards std: 0.1156589537858963
any NaN in rewards: False
tensor([[ 0.0674,  0.0040, -0.2706,  ...,  0.0272, -0.1161,  0.1386],
        [-0.0188,  0.0375, -0.1312,  ...,  0.0344, -0.1012,  0.1554],
        [ 0.1575, -0.0701, -0.2617,  ...,  0.0641, -0.1116,  0.1200],
        ...,
        [ 0.0461,  0.1124, -0.1198,  ...,  0.0152, -0.1182,  0.0223],
        [ 0.0043,  0.0185, -0.2964,  ...,  0.0521, -0.0151,  0.0739],
        [ 0.1856, -0.1344, -0.2754,  ..., -0.0162, -0.1247,  0.1785]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0674,  0.0040, -0.2706,  ...,  0.0272, -0.1161,  0.1386],
        [-0.0188,  0.0375, -0.1312,  ...,  0.0344, -0.1012,  0.1554],
        [ 0.1575, -0.0701, -0.2617,  ...,  0.0641, -0.1116,  0.1200],
        ...,
        [ 0.0461,  0.1124, -0.1198,  ...,  0.0152, -0.1182,  0.0223],
        [ 0.0043,  0.0185, -0.2964,  ...,  0.0521, -0.0151,  0.0739],
        [ 0.1856, -0.1344, -0.2754,  ..., -0.0162, -0.1247,  0.1785]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0674,  0.0040, -0.2706,  ...,  0.0272, -0.1161,  0.1386],
        [-0.0188,  0.0375, -0.1312,  ...,  0.0344, -0.1012,  0.1554],
        [ 0.1575, -0.0701, -0.2617,  ...,  0.0641, -0.1116,  0.1200],
        ...,
        [ 0.0461,  0.1124, -0.1198,  ...,  0.0152, -0.1182,  0.0223],
        [ 0.0043,  0.0185, -0.2964,  ...,  0.0521, -0.0151,  0.0739],
        [ 0.1856, -0.1344, -0.2754,  ..., -0.0162, -0.1247,  0.1785]],
       device='cuda:0')
torch.Size([64, 30])
ppo update
🔍 rewards: tensor([0.6743, 0.4885, 0.5445, 0.7692, 0.4227, 0.6289, 0.6770, 0.7063, 0.6363,
        0.6441, 0.6911, 0.7300, 0.7930, 0.8124, 0.7788, 0.2881, 0.7921, 0.8412,
        0.3264, 0.7977, 0.2616, 0.2449, 0.7640, 0.3306, 0.3527, 0.7543, 0.3787,
        0.7137, 0.3820, 0.4830, 0.5187, 0.4591, 0.5265, 0.6242, 0.5268, 0.4589,
        0.4990, 0.6515, 0.3418, 0.3666, 0.4276, 0.7431, 0.4629, 0.6804, 0.6843,
        0.6902, 0.7040, 0.5975, 0.6795, 0.4680, 0.7467, 0.6397, 0.3896, 0.7542,
        0.4390, 0.6490, 0.6664, 0.7166, 0.7444, 0.3331, 0.4267, 0.6684, 0.6404,
        0.4204], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5789623260498047
rewards std: 0.16346117854118347
any NaN in rewards: False
tensor([[ 0.1102,  0.1490, -0.0945,  ...,  0.2707,  0.0921,  0.1795],
        [ 0.1666,  0.0046, -0.2527,  ..., -0.0387, -0.0861,  0.0825],
        [ 0.1436, -0.0119, -0.3085,  ..., -0.0579, -0.1372,  0.0618],
        ...,
        [ 0.0244, -0.0506, -0.3305,  ..., -0.0896, -0.3276,  0.1849],
        [-0.0147, -0.2629, -0.2265,  ..., -0.0039, -0.0919,  0.1754],
        [ 0.0354, -0.2027, -0.2396,  ...,  0.0445, -0.0799,  0.2089]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.1102,  0.1490, -0.0945,  ...,  0.2707,  0.0921,  0.1795],
        [ 0.1666,  0.0046, -0.2527,  ..., -0.0387, -0.0861,  0.0825],
        [ 0.1436, -0.0119, -0.3085,  ..., -0.0579, -0.1372,  0.0618],
        ...,
        [ 0.0244, -0.0506, -0.3305,  ..., -0.0896, -0.3276,  0.1849],
        [-0.0147, -0.2629, -0.2265,  ..., -0.0039, -0.0919,  0.1754],
        [ 0.0354, -0.2027, -0.2396,  ...,  0.0445, -0.0799,  0.2089]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.1102,  0.1490, -0.0945,  ...,  0.2707,  0.0921,  0.1795],
        [ 0.1666,  0.0046, -0.2527,  ..., -0.0387, -0.0861,  0.0825],
        [ 0.1436, -0.0119, -0.3085,  ..., -0.0579, -0.1372,  0.0618],
        ...,
        [ 0.0244, -0.0506, -0.3305,  ..., -0.0896, -0.3276,  0.1849],
        [-0.0147, -0.2629, -0.2265,  ..., -0.0039, -0.0919,  0.1754],
        [ 0.0354, -0.2027, -0.2396,  ...,  0.0445, -0.0799,  0.2089]],
       device='cuda:0')
torch.Size([64, 30])
precision: 0.5340501792114696
recall: 0.5643939393939394
auc: 0.5370287520878072
accuracy: 0.527027027027027
f1: 0.5488029465930019
confusion matrix:
[[124 130]
 [115 149]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:11<00:00, 23.17it/s]
precision: 0.7666666666666667
recall: 0.1796875
auc: 0.6816105769230769
accuracy: 0.5658914728682171
f1: 0.2911392405063291
confusion matrix:
[[123   7]
 [105  23]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:10<00:00, 24.00it/s]
precision: 0.7222222222222222
recall: 0.23214285714285715
auc: 0.7348336594911937
accuracy: 0.627906976744186
f1: 0.35135135135135137
confusion matrix:
[[136  10]
 [ 86  26]]
Save model at epoch 0.
val auc: 0.6816105769230769
 12%|██████████████████▋                                                                                                                                            | 61/518 [00:02<00:18, 25.37it/s]
ppo update
🔍 rewards: tensor([0.6572, 0.6456, 0.6058, 0.5771, 0.6251, 0.4590, 0.6043, 0.5832, 0.5487,
        0.5613, 0.5402, 0.6454, 0.6177, 0.6823, 0.6972, 0.6293, 0.6809, 0.5900,
        0.5464, 0.5830, 0.5019, 0.5827, 0.6076, 0.5941, 0.6768, 0.4231, 0.6411,
        0.4779, 0.4223, 0.6912, 0.5005, 0.5546, 0.6242, 0.6154, 0.5868, 0.5053,
        0.6219, 0.5098, 0.7729, 0.7175, 0.6330, 0.4167, 0.3827, 0.4438, 0.7032,
        0.6600, 0.6603, 0.8223, 0.3789, 0.4856, 0.4975, 0.4182, 0.6423, 0.5780,
        0.5852, 0.7848, 0.5243, 0.6180, 0.4722, 0.6223, 0.4943, 0.5745, 0.4481,
        0.5786], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5801910161972046
rewards std: 0.09681906551122665
any NaN in rewards: False
tensor([[ 0.0876,  0.0243, -0.2810,  ..., -0.0549, -0.0976,  0.1519],
        [-0.0239,  0.0425, -0.2910,  ..., -0.0851, -0.0317,  0.0989],
        [ 0.0158, -0.1188, -0.2473,  ...,  0.1975,  0.0256,  0.1913],
        ...,
        [ 0.0137,  0.0217, -0.2023,  ..., -0.0792, -0.0616,  0.1921],
        [ 0.1896,  0.0285, -0.1538,  ...,  0.0078, -0.0607,  0.0358],
        [ 0.3768,  0.4205, -0.1986,  ...,  0.3046,  0.0788,  0.2253]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0876,  0.0243, -0.2810,  ..., -0.0549, -0.0976,  0.1519],
        [-0.0239,  0.0425, -0.2910,  ..., -0.0851, -0.0317,  0.0989],
        [ 0.0158, -0.1188, -0.2473,  ...,  0.1975,  0.0256,  0.1913],
        ...,
        [ 0.0137,  0.0217, -0.2023,  ..., -0.0792, -0.0616,  0.1921],
        [ 0.1896,  0.0285, -0.1538,  ...,  0.0078, -0.0607,  0.0358],
        [ 0.3768,  0.4205, -0.1986,  ...,  0.3046,  0.0788,  0.2253]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0876,  0.0243, -0.2810,  ..., -0.0549, -0.0976,  0.1519],
        [-0.0239,  0.0425, -0.2910,  ..., -0.0851, -0.0317,  0.0989],
        [ 0.0158, -0.1188, -0.2473,  ...,  0.1975,  0.0256,  0.1913],
        ...,
        [ 0.0137,  0.0217, -0.2023,  ..., -0.0792, -0.0616,  0.1921],
        [ 0.1896,  0.0285, -0.1538,  ...,  0.0078, -0.0607,  0.0358],
        [ 0.3768,  0.4205, -0.1986,  ...,  0.3046,  0.0788,  0.2253]],
       device='cuda:0')
torch.Size([64, 30])
ppo update
🔍 rewards: tensor([0.4862, 0.6135, 0.6751, 0.5497, 0.6401, 0.7488, 0.4815, 0.6118, 0.5013,
        0.5656, 0.5279, 0.4506, 0.6067, 0.5145, 0.3809, 0.6387, 0.4084, 0.4446,
        0.5620, 0.6032, 0.6813, 0.5789, 0.4766, 0.6697, 0.5118, 0.4993, 0.5572,
        0.6261, 0.6334, 0.6389, 0.3737, 0.6750, 0.7316, 0.7382, 0.6943, 0.6796,
        0.5464, 0.3634, 0.7053, 0.8510, 0.7830, 0.3478, 0.8222, 0.8728, 0.8229,
        0.8057, 0.8395, 0.8553, 0.2386, 0.3364, 0.8702, 0.2980, 0.4332, 0.8004,
        0.3579, 0.3202, 0.7630, 0.6722, 0.5117, 0.4251, 0.5809, 0.5777, 0.4228,
        0.3931], device='cuda:0')
rewards.shape: torch.Size([64])
rewards mean: 0.5842630863189697
rewards std: 0.16146695613861084
any NaN in rewards: False
tensor([[ 0.0261, -0.0755, -0.3183,  ..., -0.1529, -0.1818,  0.2526],
        [ 0.1003,  0.0404, -0.2380,  ..., -0.0918, -0.0698,  0.1176],
        [ 0.2691, -0.2258, -0.4014,  ...,  0.1256, -0.0636,  0.5559],
        ...,
        [-0.0944,  0.0092, -0.3753,  ...,  0.0819,  0.0335,  0.0920],
        [ 0.0623,  0.0360, -0.1565,  ...,  0.1540,  0.0623, -0.0167],
        [ 0.1856, -0.1344, -0.2754,  ..., -0.0162, -0.1247,  0.1785]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0261, -0.0755, -0.3183,  ..., -0.1529, -0.1818,  0.2526],
        [ 0.1003,  0.0404, -0.2380,  ..., -0.0918, -0.0698,  0.1176],
        [ 0.2691, -0.2258, -0.4014,  ...,  0.1256, -0.0636,  0.5559],
        ...,
        [-0.0944,  0.0092, -0.3753,  ...,  0.0819,  0.0335,  0.0920],
        [ 0.0623,  0.0360, -0.1565,  ...,  0.1540,  0.0623, -0.0167],
        [ 0.1856, -0.1344, -0.2754,  ..., -0.0162, -0.1247,  0.1785]],
       device='cuda:0')
torch.Size([64, 30])
tensor([[ 0.0261, -0.0755, -0.3183,  ..., -0.1529, -0.1818,  0.2526],
        [ 0.1003,  0.0404, -0.2380,  ..., -0.0918, -0.0698,  0.1176],
        [ 0.2691, -0.2258, -0.4014,  ...,  0.1256, -0.0636,  0.5559],
        ...,
        [-0.0944,  0.0092, -0.3753,  ...,  0.0819,  0.0335,  0.0920],
        [ 0.0623,  0.0360, -0.1565,  ...,  0.1540,  0.0623, -0.0167],
        [ 0.1856, -0.1344, -0.2754,  ..., -0.0162, -0.1247,  0.1785]],
       device='cuda:0')
torch.Size([64, 30])
Traceback (most recent call last):
  File "/work/PAMIL_two_round/train.py", line 88, in <module>
    main(args)
  File "/work/PAMIL_two_round/train.py", line 81, in main
    train(args,basedmodel,ppo,classifier_chief, classifier_giga,FusionHisF, gigapath_model, memory,train_dataloader, validation_dataloader, test_dataloader, wandb)
  File "/work/PAMIL_two_round/utilmodule/core.py", line 312, in train
    wsi_embedding_gigapath = gigapath_wsi_embedding(gigapath_model, torch.cat(memory.select_gigapath_feature_pool, dim=1), torch.cat(memory.coords_actions, dim=1))
  File "/work/PAMIL_two_round/utilmodule/core.py", line 137, in gigapath_wsi_embedding
    wsi_feature_emb = run_inference_with_slide_encoder(slide_encoder_model=gigapath_model, tile_embeds=feature, coords=coords)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/work/PAMIL_two_round/gigapath/pipeline.py", line 187, in run_inference_with_slide_encoder
    slide_embeds = slide_encoder_model(tile_embeds.cuda(), coords.cuda(), all_layer_embed=True)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/PAMIL_two_round/gigapath/slide_encoder.py", line 209, in forward
    x_list = self.encoder(src_tokens=None, token_embeddings=x, return_all_hiddens=all_layer_embed)["encoder_states"]
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/PAMIL_two_round/gigapath/torchscale/model/../../torchscale/architecture/encoder.py", line 374, in forward
    x, l_aux_i = layer(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/PAMIL_two_round/gigapath/torchscale/model/../../torchscale/architecture/encoder.py", line 127, in forward
    x, _ = self.self_attn(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/PAMIL_two_round/gigapath/torchscale/model/../../torchscale/component/dilated_attention.py", line 205, in forward
    out, lse = self.attention_ops(qi, ki, vi, key_padding_mask=key_padding_mask, attn_mask=attn_mask, rel_pos=rel_pos, is_causal=is_causal)
  File "/work/PAMIL_two_round/gigapath/torchscale/model/../../torchscale/component/multihead_attention.py", line 103, in attention_ops
    attn, lse = flash_attn_func(q, k, v, self.dropout, attn_mask, None, is_causal)
  File "/work/PAMIL_two_round/gigapath/torchscale/model/../../torchscale/component/flash_attention.py", line 15, in flash_attn_func
    attn, lse, _ = _flash_attn_func(q, k, v, dropout_p=dropout, softmax_scale=softmax_scale, causal=is_causal, return_attn_probs=True)
  File "/opt/conda/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 831, in flash_attn_func
    return FlashAttnFunc.apply(
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/conda/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 511, in forward
    out, q, k, v, out_padded, softmax_lse, S_dmask, rng_state = _flash_attn_forward(
  File "/opt/conda/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 51, in _flash_attn_forward
    out, q, k, v, out_padded, softmax_lse, S_dmask, rng_state = flash_attn_cuda.fwd(
KeyboardInterrupt
