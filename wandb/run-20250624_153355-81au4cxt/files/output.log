dilated_ratio:  [1, 2, 4, 8, 16]
segment_length:  [1024, 5792, 32768, 185363, 1048576]
Number of trainable LongNet parameters:  85148160
Global Pooling: False
slide_encoder.pth: 100%|█████████████████████████████████████████████████████████████████████████| 345M/345M [00:30<00:00, 11.4MB/s]
[92m Successfully Loaded Pretrained GigaPath model from hf_hub:prov-gigapath/prov-gigapath [00m
[768, 512, 256]
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 518/518 [00:31<00:00, 16.42it/s]
precision: 0.541095890410959
recall: 0.5984848484848485
auc: 0.5558488427582916
accuracy: 0.5366795366795367
f1: 0.5683453237410072
confusion matrix:
[[120 134]
 [106 158]]
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:11<00:00, 23.19it/s]
precision: 0.6146788990825688
recall: 0.5234375
auc: 0.6467548076923076
accuracy: 0.6007751937984496
f1: 0.5654008438818565
confusion matrix:
[[88 42]
 [61 67]]
 34%|████████████████████████████████▍                                                             | 89/258 [00:03<00:05, 28.80it/s]
Traceback (most recent call last):
  File "/work/PAMIL_two_round/train.py", line 88, in <module>
    main(args)
  File "/work/PAMIL_two_round/train.py", line 81, in main
    train(args,basedmodel,ppo,classifier_chief, classifier_giga,FusionHisF, gigapath_model, memory,train_dataloader, validation_dataloader, test_dataloader, wandb)
  File "/work/PAMIL_two_round/utilmodule/core.py", line 393, in train
    precision, recall, f1, auc, accuracy = test(args,basedmodel,ppo,classifier_chief,FusionHisF,memory,test_loader, chief_model, "test", epoch)
  File "/work/PAMIL_two_round/utilmodule/core.py", line 32, in test
    for idx, (coords, chief_data, gigapath_data, label) in enumerate (tqdm(test_loader)):
  File "/opt/conda/lib/python3.10/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 678, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/work/PAMIL_two_round/datasets/load_datasets.py", line 38, in __getitem__
    gigapath_features = torch.load(gigapath_feature_path)
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 809, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 1172, in _load
    result = unpickler.load()
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 1142, in persistent_load
    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 1112, in load_tensor
    storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage
KeyboardInterrupt
