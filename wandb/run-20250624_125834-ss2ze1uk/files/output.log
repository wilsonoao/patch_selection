[768, 512, 256]
dilated_ratio:  [1, 2, 4, 8, 16]
segment_length:  [1024, 5792, 32768, 185363, 1048576]
Number of trainable LongNet parameters:  85148160
Global Pooling: False
slide_encoder.pth: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 345M/345M [00:31<00:00, 10.9MB/s]
[92m Successfully Loaded Pretrained GigaPath model from hf_hub:prov-gigapath/prov-gigapath [00m
  0%|                                                                                                               | 0/518 [00:00<?, ?it/s]
torch.Size([1, 1, 2])
torch.Size([1, 1, 2])
0.0
Traceback (most recent call last):
  File "/work/PAMIL_two_round/train.py", line 84, in <module>
    main(args)
  File "/work/PAMIL_two_round/train.py", line 77, in main
    train(args,basedmodel,ppo,classifier_chief, classifier_giga,FusionHisF, , memory,train_dataloader, validation_dataloader, test_dataloader, wandb)
  File "/work/PAMIL_two_round/utilmodule/core.py", line 377, in train
    ppo.update(memory)
  File "/work/PAMIL_GIGAPATH_CHIEF/models/DPSF.py", line 238, in update
    old_logprobs = torch.stack(memory.logprobs[:], 0).cuda().detach()
RuntimeError: stack expects each tensor to be equal size, but got [1, 10] at entry 0 and [1] at entry 1
