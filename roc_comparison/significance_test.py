import os
import pandas as pd
import numpy as np
from compare_auc_delong_xu import delong_roc_test  # ä½ å·²ç¶“æœ‰é€™å€‹å‡½æ•¸
from sklearn.metrics import roc_auc_score

tumor_name = "TTN"

# è¨­å®šå››å€‹foldçš„è·¯å¾‘
fold_root_1 = '/work/PAMIL_two_round/result_ensemble/' + tumor_name
fold_root_2 = '/work/weight/CHIEF_WSI_baseline/' + tumor_name

y_true_all = []
y_pred_1_all = []
y_pred_2_all = []

for fold_id in range(4):
    path_1 = os.path.join(fold_root_1, f'dataset_fold_{fold_id}', 'probability.csv')
    path_2 = os.path.join(fold_root_2, f'dataset_fold_{fold_id}', 'probability.csv')

    df1 = pd.read_csv(path_1)
    df2 = pd.read_csv(path_2)

    assert np.array_equal(df1['label'].values, df2['label'].values), f"fold {fold_id} label mismatch!"

    y_true_all.append(df1['label'].values)
    y_pred_1_all.append(df1['prob'].values)
    y_pred_2_all.append(df2['prob'].values)

# åˆä½µå››å€‹ fold çš„è³‡æ–™
y_true = np.concatenate(y_true_all)
y_pred_1 = np.concatenate(y_pred_1_all)
y_pred_2 = np.concatenate(y_pred_2_all)

# è¨ˆç®—æ‹¼æ¥å¾Œçš„ AUC
auc_1 = roc_auc_score(y_true, y_pred_1)
auc_2 = roc_auc_score(y_true, y_pred_2)

print(f"ğŸ“ˆ æ‹¼æ¥å¾Œ New method AUC: {auc_1:.6f}")
print(f"ğŸ“ˆ æ‹¼æ¥å¾Œ baseline AUC: {auc_2:.6f}")

# åŸ·è¡Œ DeLong test
log10_p = delong_roc_test(y_true, y_pred_1, y_pred_2)
p_value = 10 ** log10_p

print(f"ğŸ“Š DeLong Test log10(p-value): {log10_p}")
print(f"ğŸ“Š DeLong Test p-value: {p_value.item():.6f}")

# é¡¯è‘—æ€§åˆ¤æ–·
if p_value < 0.05:
    print("âœ… çµè«–ï¼šå…©å€‹æ¨¡å‹çš„ AUC å·®ç•°å…·æœ‰çµ±è¨ˆé¡¯è‘—æ€§")
else:
    print("âŒ çµè«–ï¼šç„¡æ³•ç¢ºèªå…©å€‹æ¨¡å‹çš„ AUC æœ‰é¡¯è‘—å·®ç•°")
